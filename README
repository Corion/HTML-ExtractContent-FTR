NAME

    HTML::ExtractContent::FTR - extract content using Full-Text-RSS rules

SYNOPSIS

      use HTML::ExtractContent::FTR;
      use LWP::UserAgent;
    
      my $agent = LWP::UserAgent->new;
      my $res = $agent->get('http://www.example.com/');
    
      my $extractor = HTML::ExtractContent::FTR->new;
      my $info = $extractor->extract($res->decoded_content, url => $url);
      print $info->title, "\n";
      print $info->as_text, "\n";

 $extractor->can_extract %options

      if( $extractor->can_extract(url => 'http://example.com/foo' )) {
          ...
      };

    Returns whether the extractor has a set of rules for extracting
    content. This is convenient as a sanity check before you make a long
    network request.

 $extractor->extract $html, %options

      my $info = $extractor->extract($html, url => 'http://example.com/foo' );
      if( $info ) {
          print $info->title, "\n";
          print $info->as_text, "\n";
      };

 ->_compile_selector_fetch

    The internal generator for compiling a rule that fetches an XPath
    selector and stores it as an attribute.

    This routine should also take care that we only select the ancestor
    node if two nodes get selected and one is a descendant of the other.

 ->compile_if_page_contains

    A no-op currently, until I figure out how to structure conditional
    statements

 ->compile_strip

    Strip all elements from the page that match a selector

SEE ALSO

    http://help.fivefilters.org/customer/portal/articles/223153-site-patter
    ns

    https://github.com/fivefilters/ftr-site-config

    1;

